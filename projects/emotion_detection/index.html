<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Training and Deploying a Machine Learning Model using TensorFlow and Flask | Morris John Montemayor</title> <meta name="author" content="Morris John Montemayor"> <meta name="description" content="i created a simple machine learning model for emotion detection with tensorflow and deployed it using flask"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%90%93&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://studentmorrisjohn.github.io/projects/emotion_detection/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Morris John Montemayor</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <article> <h1 id="training-and-deploying-a-machine-learning-model-using-tensorflow-and-flask">Training and Deploying a Machine Learning Model using TensorFlow and Flask</h1> <p>I created a simple tool that takes in a picture of a person as an input then tries to predict the facial expression that person is showing. I used Google Colab to train the model and deployed it to a simple flask app with the help of pythonanywhere.</p> <p>The model was not very accurate when I tested it using different pictures of myself. Improving the dataset and playing around with the neural network can improve the accuracy of the model. This project focused more on learning how to execute the whole machine learning workflow. Starting from training a machine learning model to deploying it as an API.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/demo-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/demo-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/demo-1400.webp"></source> <img src="/assets/img/demo.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="code-and-demo">Code and Demo</h3> <p>The code for the training and deployment can be found at this <a href="https://github.com/studentmorrisjohn/emotion_detection" rel="external nofollow noopener" target="_blank">github repository</a>. A simple <a href="#demo">demo</a> of the tool can be found at the bottom of this page.</p> <h3 id="data-set">Data Set</h3> <p>I’ve used a Convolutional Neural Network, or CNN, to recognize seven types of expression: angry, disgust, fear, happy, sad, surprise, neutral. The model will be trained on the <a href="https://www.kaggle.com/datasets/msambare/fer2013" rel="external nofollow noopener" target="_blank">FER 2013 Dataset</a> The data consists of 48x48 pixel grayscale images of faces. The training set consists of 28,709 examples and the public test set consists of 3,589 examples.</p> <h3 id="pipeline">Pipeline</h3> <p>I trained the model on V100 GPU on Google Colab Pro using keras and served the resulting model as an API by creating a simple Flask APP deployed on pythonanywhere.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/pipeline-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/pipeline-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/pipeline-1400.webp"></source> <img src="/assets/img/pipeline.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="training-on-google-colab-pro">Training on Google Colab Pro</h3> <p>Google Colab, is a free, cloud-based platform provided by Google that allows users to write and execute Python code in a collaborative environment. It is built on top of Jupyter Notebooks and provides a similar interface, making it easy for users to write and execute code in a step-by-step manner.</p> <p>I subscribed to Colab pro to have access to larger RAM and faster GPU runtimes. But this project can also be done on the free version of Colab.</p> <h4 id="imports">Imports</h4> <p>For this project, I’ve used keras, tensorflow, opencv, and numpy for training the data. Matplotlib was used for some visualization but was not used in the actual training of the model.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
<span class="kn">from</span> <span class="n">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span>

<span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div> <h4 id="loading-the-data">Loading the Data</h4> <p>I’ve gotten the dataset from kaggle and downloaded it as a zip file. I then uploaded that zip file to Google Colab. After uploading I unzipped the file and gotten two folders for the training set and the test set.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>!unzip /content/fer2013.zip
</code></pre></div></div> <p>The dataset is separated into to folders, a training set and a test set. This made the splitting of the data for training and validation easier. I just loaded the images from the training folder using opencv and put it in a list called training data. Then extracted the x and y. I implemented the same way of loading for the test data.</p> <p>***Setting the variables</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># directory variable
</span><span class="n">dataDirectory</span> <span class="o">=</span> <span class="sh">"</span><span class="s">train/</span><span class="sh">"</span>
<span class="n">dataDirectoryTest</span> <span class="o">=</span> <span class="sh">"</span><span class="s">test/</span><span class="sh">"</span>

<span class="c1"># expression categories
</span><span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">angry</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">disgust</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">fear</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">happy</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">neutral</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">sad</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">surprise</span><span class="sh">"</span><span class="p">]</span>

<span class="c1"># image size the images will be resized to for the processing
</span><span class="n">img_size</span> <span class="o">=</span> <span class="mi">224</span>

<span class="c1"># initialize variables
</span><span class="n">trainingData</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">testData</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div></div> <p><strong><em>Loading the training data</em></strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">category</span> <span class="ow">in</span> <span class="n">categories</span><span class="p">:</span>
<span class="err"> </span> <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">dataDirectory</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span>
<span class="err"> </span> <span class="n">class_num</span> <span class="o">=</span> <span class="n">categories</span><span class="p">.</span><span class="nf">index</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
<span class="err"> </span> <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>

<span class="err"> </span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">try</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="n">count</span> <span class="o">==</span> <span class="mi">436</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">break</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> 
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">img_array</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span><span class="n">img</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">new_array</span><span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">img_array</span><span class="p">,(</span><span class="n">img_size</span><span class="p">,</span><span class="n">img_size</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">trainingData</span><span class="p">.</span><span class="nf">append</span><span class="p">([</span><span class="n">new_array</span><span class="p">,</span><span class="n">class_num</span><span class="p">])</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> 
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="err"> </span> <span class="err"> </span> <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">pass</span>
</code></pre></div></div> <p>For the loading of the test data, I’ve put a limit of 436 for the total maximum number of data per classification. The reason behind this is that the amount of pictures per classification was not the same. I used 436 because this is the size of the classification, disgust, with the fewest data. I did not impose this limit on the test data since it will not affect the training of the model.</p> <p><strong><em>Loading the test data</em></strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># looping through each category in the directory
</span><span class="k">for</span> <span class="n">category</span> <span class="ow">in</span> <span class="n">categories</span><span class="p">:</span>
<span class="err"> </span> <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">dataDirectoryTest</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span>
<span class="err"> </span> <span class="n">class_num</span> <span class="o">=</span> <span class="n">categories</span><span class="p">.</span><span class="nf">index</span><span class="p">(</span><span class="n">category</span><span class="p">)</span>
<span class="err"> </span> 
<span class="err"> </span> <span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">try</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">img_array</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span><span class="n">img</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">new_array</span><span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">img_array</span><span class="p">,(</span><span class="n">img_size</span><span class="p">,</span><span class="n">img_size</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">testData</span><span class="p">.</span><span class="nf">append</span><span class="p">([</span><span class="n">new_array</span><span class="p">,</span><span class="n">class_num</span><span class="p">])</span>

<span class="err"> </span> <span class="err"> </span> <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">pass</span>
</code></pre></div></div> <p><strong><em>Extracting the features and label from the data sets</em></strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># instantiating the x and y variables
</span><span class="n">x</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">x_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># extracting the features and label from the training data and test data
</span><span class="k">for</span> <span class="n">features</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">trainingData</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">x</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">y</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

<span class="k">for</span> <span class="n">features</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">testData</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">x_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">y_test</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
</code></pre></div></div> <h4 id="preprocessing-the-data">Preprocessing the Data</h4> <p>I reshaped the data in the format accepted by the model we will be using The model will take batches of the shape <code class="language-plaintext highlighter-rouge">[N, 224, 224, 3]</code> and outputs probabilities of the shape <code class="language-plaintext highlighter-rouge">[N, 7]</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># reshaping and normalization
</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">x_test</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="o">/</span><span class="mf">255.0</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">/</span><span class="mf">255.0</span>

<span class="c1"># converting the list to np array
</span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div> <h4 id="creating-the-model">Creating the model</h4> <p>I created a simple convolutional neural network based off of MobileNet. A CNN model which is known for their efficiency and suitability for deployment on devices with limited computational resources. The following model contains 2 activation layers and 3 dense layers.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># base model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">applications</span><span class="p">.</span><span class="nc">MobileNetV2</span><span class="p">()</span>
<span class="n">base_input</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nb">input</span>
<span class="n">base_output</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">].</span><span class="n">output</span>

<span class="c1"># layers to modify the base model
</span><span class="n">final_output</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">)(</span><span class="n">base_output</span><span class="p">)</span>
<span class="n">final_ouput</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Activation</span><span class="p">(</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">final_output</span><span class="p">)</span>
<span class="n">final_output</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">)(</span><span class="n">final_ouput</span><span class="p">)</span>
<span class="n">final_ouput</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Activation</span><span class="p">(</span><span class="sh">'</span><span class="s">relu</span><span class="sh">'</span><span class="p">)(</span><span class="n">final_output</span><span class="p">)</span>
<span class="n">final_output</span> <span class="o">=</span> <span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="sh">'</span><span class="s">softmax</span><span class="sh">'</span><span class="p">)(</span><span class="n">final_ouput</span><span class="p">)</span>

<span class="c1"># creating a new model out of the old model using the layers to modify the model
</span><span class="n">new_model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">base_input</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">final_output</span><span class="p">)</span>
<span class="n">new_model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="sh">"</span><span class="s">sparse_categorical_crossentropy</span><span class="sh">"</span><span class="p">,</span> <span class="n">optimizer</span> <span class="o">=</span> <span class="sh">"</span><span class="s">adam</span><span class="sh">"</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">accuracy</span><span class="sh">"</span><span class="p">]</span> <span class="p">)</span>
</code></pre></div></div> <h4 id="fit-and-validate">Fit and Validate</h4> <p>After defining the model, I trained the model for 25 epochs. And validated it using the test data</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># training the model
</span><span class="n">new_model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">25</span><span class="p">)</span>

<span class="c1"># evaluating the model
</span><span class="n">score</span> <span class="o">=</span> <span class="n">new_model</span><span class="p">.</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</code></pre></div></div> <h4 id="saving-the-model-for-the-api">Saving the model for the API</h4> <p>After the training and validation of the model, I saved the model into an h5 file. I will use this file to make predictions using my API.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_model</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">"</span><span class="s">emotiondetection.h5</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h3 id="deploying-using-flask-and-pythonanywhere">Deploying using Flask and PythonAnywhere</h3> <p>I created a simple API endpoint where I can send a picture and the flask app will execute the code to make a prediction. Flask is a lightweight and web framework for Python that is designed to be simple and easy to use. It is widely used for developing web applications, APIs (Application Programming Interfaces), and other web-related projects.</p> <p>To host this flask app and be accessible through the internet, I used pythonanywhere. PythonAnywhere is an online platform that provides a Python development environment in the cloud. It allows users to write, run, and host Python applications without the need for local installations or server management.</p> <h4 id="imports-1">Imports</h4> <p>For the simple flask api, I used flask, pillow, tensorflow, opencv, and numpy</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">flask</span> <span class="kn">import</span> <span class="n">Flask</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">render_template</span><span class="p">,</span> <span class="n">jsonify</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="n">io</span> <span class="kn">import</span> <span class="n">BytesIO</span>

<span class="kn">import</span> <span class="n">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">os</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div> <h4 id="loading-the-model">Loading the Model</h4> <p>To load the model into the app, I used karas <code class="language-plaintext highlighter-rouge">load_model</code> method.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">new_model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">/path/to/emotiondetection.h5</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h4 id="processing-the-image">Processing the image</h4> <p>Before making a prediction using the model, I needed to do three things. First is to turn the whole picture into a grayscale image. Next is to detect the face of the person in the picture. For this, I have used open cv’s cascade classifier. Lastly is to preprocess the picture of the face to match the format needed by the model. To do this, I zoomed in on the detected face and resized the picture.</p> <p><strong><em>Turning into grayscale</em></strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Converting image to grayscale
</span><span class="n">gray_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>
</code></pre></div></div> <p><strong><em>Face Detection</em></strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Reading the image
</span><span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">image</span><span class="p">),</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_RGB2BGR</span><span class="p">)</span>

<span class="c1"># Loading the required haar-cascade xml classifier file
</span><span class="n">haar_cascade</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">CascadeClassifier</span><span class="p">(</span><span class="sh">'</span><span class="s">/path/to/haarcascade_frontalface_default.xml</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># Applying the face detection method on the grayscale image
</span>
<span class="n">faces_rect</span> <span class="o">=</span> <span class="n">haar_cascade</span><span class="p">.</span><span class="nf">detectMultiScale</span><span class="p">(</span><span class="n">gray_img</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
</code></pre></div></div> <p><strong><em>Zooming and Resizing</em></strong></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Zooming in on face
</span><span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">h</span> <span class="ow">in</span> <span class="n">faces_rect</span><span class="p">:</span>
	<span class="n">roi_gray</span> <span class="o">=</span> <span class="n">gray_img</span><span class="p">[</span><span class="n">y</span><span class="p">:</span><span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">]</span>
	<span class="n">roi_color</span> <span class="o">=</span> <span class="n">img</span><span class="p">[</span><span class="n">y</span><span class="p">:</span><span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">]</span>
	<span class="n">cv2</span><span class="p">.</span><span class="nf">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">),</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
	<span class="n">facess</span> <span class="o">=</span> <span class="n">haar_cascade</span><span class="p">.</span><span class="nf">detectMultiScale</span><span class="p">(</span><span class="n">roi_gray</span><span class="p">)</span>
	
	<span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">facess</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
		<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Face not detected</span><span class="sh">"</span><span class="p">)</span>
	<span class="k">else</span><span class="p">:</span>
		<span class="nf">for</span><span class="p">(</span><span class="n">ex</span><span class="p">,</span><span class="n">ey</span><span class="p">,</span><span class="n">ew</span><span class="p">,</span><span class="n">eh</span><span class="p">)</span> <span class="ow">in</span> <span class="n">facess</span><span class="p">:</span>
			<span class="n">face_roi</span> <span class="o">=</span> <span class="n">roi_color</span><span class="p">[</span><span class="n">ey</span><span class="p">:</span> <span class="n">ey</span><span class="o">+</span><span class="n">eh</span><span class="p">,</span> <span class="n">ex</span><span class="p">:</span> <span class="n">ex</span><span class="o">+</span><span class="n">ew</span><span class="p">]</span>

<span class="c1"># Resizing image before making a prediction
</span><span class="n">final_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">face_roi</span><span class="p">,</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">))</span>
<span class="n">final_image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">final_image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">final_image</span> <span class="o">=</span> <span class="n">final_image</span><span class="o">/</span><span class="mf">255.0</span>
</code></pre></div></div> <h4 id="making-a-prediction">Making a prediction</h4> <p>After the preprocessing stage, I used the <code class="language-plaintext highlighter-rouge">predict</code> method built in to the loaded model. This will return a numpy array of the different scores for the classifications. I used argmax to determine which of the classification has the highest score. Then I use this as an index to get the name of the classification in a classifications list.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">angry</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">disgust</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">fear</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">happy</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">neutral</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">sad</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">surprise</span><span class="sh">"</span><span class="p">]</span>

<span class="n">prediction</span> <span class="o">=</span> <span class="n">classes</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">Predictions</span><span class="p">)]</span>
</code></pre></div></div> <p>![[Pasted image 20231114143633.png]] <em>Result of the training</em></p> <h4 id="creating-the-make_predicton-method">Creating the <code class="language-plaintext highlighter-rouge">make_predicton</code> method</h4> <p>I then put the loading of the model, processing of the image, and the making of prediction in to a function called <code class="language-plaintext highlighter-rouge">make_prediction</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">make_prediction</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="c1"># Load the model
</span><span class="err"> </span> <span class="err"> </span> <span class="n">new_model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="nf">load_model</span><span class="p">(</span><span class="sh">"</span><span class="s">/path/to/emotiondetection.h5</span><span class="sh">"</span><span class="p">)</span>

<span class="err"> </span> <span class="err"> </span> <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">angry</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">disgust</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">fear</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">happy</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">neutral</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">sad</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">surprise</span><span class="sh">"</span><span class="p">]</span>
<span class="err"> </span> <span class="err"> </span> 
<span class="err"> </span> <span class="err"> </span> <span class="c1"># Reading the image
</span><span class="err"> </span> <span class="err"> </span> <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">image</span><span class="p">),</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_RGB2BGR</span><span class="p">)</span>

<span class="err"> </span> <span class="err"> </span> <span class="c1"># Converting image to grayscale
</span><span class="err"> </span> <span class="err"> </span> <span class="n">gray_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">cvtColor</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLOR_BGR2GRAY</span><span class="p">)</span>

<span class="err"> </span> <span class="err"> </span> <span class="c1"># Loading the required haar-cascade xml classifier file
</span><span class="err"> </span> <span class="err"> </span> <span class="n">haar_cascade</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nc">CascadeClassifier</span><span class="p">(</span><span class="sh">'</span><span class="s">/path/to/haarcascade_frontalface_default.xml</span><span class="sh">'</span><span class="p">)</span>

<span class="err"> </span> <span class="err"> </span> <span class="c1"># Applying the face detection method on the grayscale image
</span><span class="err"> </span> <span class="err"> </span> <span class="n">faces_rect</span> <span class="o">=</span> <span class="n">haar_cascade</span><span class="p">.</span><span class="nf">detectMultiScale</span><span class="p">(</span><span class="n">gray_img</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>

<span class="err"> </span> <span class="err"> </span> <span class="c1"># Zooming in on face
</span><span class="err"> </span> <span class="err"> </span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">h</span> <span class="ow">in</span> <span class="n">faces_rect</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">roi_gray</span> <span class="o">=</span> <span class="n">gray_img</span><span class="p">[</span><span class="n">y</span><span class="p">:</span><span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">]</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">roi_color</span> <span class="o">=</span> <span class="n">img</span><span class="p">[</span><span class="n">y</span><span class="p">:</span><span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">]</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">cv2</span><span class="p">.</span><span class="nf">rectangle</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">w</span><span class="p">,</span> <span class="n">y</span><span class="o">+</span><span class="n">h</span><span class="p">),</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> 
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">facess</span> <span class="o">=</span> <span class="n">haar_cascade</span><span class="p">.</span><span class="nf">detectMultiScale</span><span class="p">(</span><span class="n">roi_gray</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> 
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">facess</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Face not detected</span><span class="sh">"</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">else</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="nf">for</span><span class="p">(</span><span class="n">ex</span><span class="p">,</span><span class="n">ey</span><span class="p">,</span><span class="n">ew</span><span class="p">,</span><span class="n">eh</span><span class="p">)</span> <span class="ow">in</span> <span class="n">facess</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">face_roi</span> <span class="o">=</span> <span class="n">roi_color</span><span class="p">[</span><span class="n">ey</span><span class="p">:</span> <span class="n">ey</span><span class="o">+</span><span class="n">eh</span><span class="p">,</span> <span class="n">ex</span><span class="p">:</span> <span class="n">ex</span><span class="o">+</span><span class="n">ew</span><span class="p">]</span>

<span class="err"> </span> <span class="err"> </span> <span class="c1"># Resizing image before making a prediction
</span><span class="err"> </span> <span class="err"> </span> <span class="n">final_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">face_roi</span><span class="p">,</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">))</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">final_image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">final_image</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">final_image</span> <span class="o">=</span> <span class="n">final_image</span><span class="o">/</span><span class="mf">255.0</span>
<span class="err"> </span> <span class="err"> </span> 
<span class="err"> </span> <span class="err"> </span> <span class="c1"># Making the Prediction
</span><span class="err"> </span> <span class="err"> </span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">new_model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">final_image</span><span class="p">)</span>

<span class="err"> </span> <span class="err"> </span> <span class="n">prediction</span> <span class="o">=</span> <span class="n">classes</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">)]</span>

<span class="err"> </span> <span class="err"> </span> <span class="k">return</span>  <span class="n">prediction</span>
</code></pre></div></div> <h4 id="creating-the-api-endpoint">Creating the API Endpoint</h4> <p>I created a route that will accept a <code class="language-plaintext highlighter-rouge">POST</code> request with an image in its body. It will then process the said image and use the <code class="language-plaintext highlighter-rouge">make_prediction</code> method to create a prediction and return it as a JSON.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nd">@app.route</span><span class="p">(</span><span class="sh">'</span><span class="s">/process_image</span><span class="sh">'</span><span class="p">,</span> <span class="n">methods</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">POST</span><span class="sh">'</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">process_image</span><span class="p">():</span>
<span class="err"> </span> <span class="err"> </span> <span class="c1"># Check if the POST request has the file part
</span><span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="sh">'</span><span class="s">file</span><span class="sh">'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">request</span><span class="p">.</span><span class="n">files</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="nf">jsonify</span><span class="p">({</span><span class="sh">'</span><span class="s">error</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">No file part</span><span class="sh">'</span><span class="p">})</span>

<span class="err"> </span> <span class="err"> </span> <span class="nb">file</span> <span class="o">=</span> <span class="n">request</span><span class="p">.</span><span class="n">files</span><span class="p">[</span><span class="sh">'</span><span class="s">file</span><span class="sh">'</span><span class="p">]</span>
<span class="err"> </span> <span class="err"> </span> 
<span class="err"> </span> <span class="err"> </span> <span class="c1"># Check if the file is empty
</span><span class="err"> </span> <span class="err"> </span> <span class="k">if</span> <span class="nb">file</span><span class="p">.</span><span class="n">filename</span> <span class="o">==</span> <span class="sh">''</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="nf">jsonify</span><span class="p">({</span><span class="sh">'</span><span class="s">error</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">No selected file</span><span class="sh">'</span><span class="p">})</span>

<span class="err"> </span> <span class="err"> </span> <span class="k">try</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="c1"># Read the image file
</span><span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="nf">open</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">image</span><span class="p">,</span> <span class="n">prediction</span> <span class="o">=</span> <span class="nf">make_prediction</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="c1"># Process the image (you can replace this with your own logic)
</span><span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">result_string</span> <span class="o">=</span> <span class="n">prediction</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="nf">jsonify</span><span class="p">({</span><span class="sh">'</span><span class="s">result</span><span class="sh">'</span><span class="p">:</span> <span class="n">result_string</span><span class="p">})</span>

<span class="err"> </span> <span class="err"> </span> <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="nf">jsonify</span><span class="p">({</span><span class="sh">'</span><span class="s">error</span><span class="sh">'</span><span class="p">:</span> <span class="nf">str</span><span class="p">(</span><span class="n">e</span><span class="p">)})</span>
</code></pre></div></div> <h4 id="deploying-to-pythonanywhere">Deploying to pythonanywhere</h4> <p>The deployment of this API to pythonanywhere is simple. I just created an account, uploaded the files to the dedicated file section. And follow the instructions detailed in their documentation on deployment of a flask app.</p> <h3 id="conclusion">Conclusion</h3> <p>This project has thought me the process of training a machine learning model and deploying it to an API. I have little experience with working on machine learning so the accuracy of the model I have trained is pretty low. You can test it in a demo below, but don’t expect it to blow your mind. This project serves only as a proof of concept. I plan on improving the accuracy and developing a user interface for an app some time later.</p> <h3 id="demo">Demo</h3> <p>To try this machine learning model out, upload a photo of a person. Make sure that the person is facing the camera and their expression is visible. Don’t upload a picture with multiple people in it.</p> <input type="file" id="imageInput" accept="image/*"> <button onclick="sendPostRequest()">Predict</button> <div id="predictionResult"></div> <img src="" id="responseImage"> <script>function predictImage(){const e=document.getElementById("imageInput"),t=document.getElementById("predictionResult");if(t.innerHTML="Predicting emotion......",e.files.length>0){const n=e.files[0],o=new FormData;o.append("file",n),fetch("https://studentmorrisjohn.pythonanywhere.com/process_image",{method:"POST",body:o}).then(e=>e.json()).then(e=>{e.error?t.innerHTML="Something went wrong! Try a different picture.":t.innerHTML=`Prediction: ${e.result}`})["catch"](e=>{console.error("Error:",e),t.innerHTML="Error predicting the image."})}else t.innerHTML="Please select an image."}async function sendPostRequest(){const e=document.getElementById("imageInput"),t=document.getElementById("predictionResult"),n=e.files[0];if(t.innerHTML="Detecting face......",n){const e=new FormData;e.append("image",n);try{const t=await fetch("https://studentmorrisjohn.pythonanywhere.com/detect_face",{method:"POST",body:e});if(t.ok){const e=await t.blob(),n=URL.createObjectURL(e);document.getElementById("responseImage").src=n,predictImage()}else console.error("Error:",t.status,t.statusText)}catch(o){console.error("Fetch error:",o)}}else console.error("No file selected.")}</script> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Morris John Montemayor. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>